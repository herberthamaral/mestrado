\documentclass[11pt]{article}
\usepackage{array}
\usepackage{mathtools}
\usepackage{epsfig,psfrag}
\usepackage{listings}
\usepackage{color}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage{lipsum} % Package to generate dummy text throughout this template
\usepackage[brazil]{babel}
\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[utf8]{inputenc}
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics
\usepackage{algpseudocode}
\usepackage{algorithmicx}

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage{multicol} % Used for the two-column layout of the document
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])
\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage{titlesec} % Allows customization of titles
\selectlanguage{brazil}

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[C]{{\vspace{-3cm}{\hspace{-4cm}\mbox{\begin{minipage}{1.5cm} \epsfxsize=2cm
\centerline{\epsffile{unimontes.eps}}
\end{minipage}}}{\hspace{.6cm} Mineração de dados $\bullet$ 2015}}
} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text




%----------------------------------------------------------------------------------------
%    TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\vspace{.5cm}\fontsize{24pt}{10pt}\selectfont\textbf{\sc Terceiro trabalho prático}} % Article title

\author{
\large
\textsc{Herberth Amaral e Marcelino Macedo}\\[2mm]
\normalsize Departamento de Ciência da Computação \\
\normalsize Universidade Estadual de Montes Claros \\
\normalsize Professor Dr. Renato Dourado Maia\\
\vspace{-5mm}
}
\date{\today}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert title

\thispagestyle{fancy} % All pages have headers and footers

\newpage

\section{Introdução}
\section{Objetivos}

Os objetivos deste trabalho são:

\begin{enumerate}
    \item Explorar opções de algoritmos de classificação;
    \item Analisar o desempenho desses algoritmos segundo critérios de precisão, tempo de treinamento e de execução.
\end{enumerate}

\section{Metodologia}

Falar que usamos validação cruzada com 10-fold.

\section{Desenvolvimento}

O presente trabalho foi desenvolvido na linguagem Python 2 e seu respectivo
código (com as devidas instruções de execução) pode ser encontrado no endereço
\url{https://github.com/herberthamaral/mestrado/tree/master/MD/pratica3}.

Ferramentas auxiliares foram utilizadas no desenvolvimento deste trabalho:

\begin{enumerate}
    \item Numpy;
    \item Scikit-learn (colocar referências);
\end{enumerate}

Todos os testes foram executados em um Intel Core i5 de segunda geração (2
processadores, 4 \textit{threads}) com 6GB de RAM.

Os seguintes algoritmos foram avaliados:

\begin{enumerate}
    \item \textit{sklearn.linear\_model.SGDClassifier};
    \item \textit{sklearn.linear\_model.Perceptron};
    \item \textit{sklearn.linear\_model.PassiveAggressiveClassifier};
    \item \textit{sklearn.lda.LDA};
    \item \textit{sklearn.kernel\_ridge.KernelRidge};
    \item \textit{sklearn.svm.SVC};
    \item \textit{sklearn.svm.NuSVC};
    \item \textit{sklearn.svm.LinearSVC};
    \item \textit{sklearn.linear\_model.SGDClassifier};
    \item \textit{sklearn.neighbors.RadiusNeighborsClassifier};
    \item \textit{sklearn.neighbors.KNeighborsClassifier};
    \item \textit{sklearn.naive\_bayes.GaussianNB};
    \item \textit{sklearn.naive\_bayes.MultinomialNB};
    \item \textit{sklearn.naive\_bayes.BernoulliNB};
    \item \textit{sklearn.tree.DecisionTreeClassifier};
    \item \textit{sklearn.ensemble.GradientBoostingClassifier};
\end{enumerate}

\subsection{Técnicas de implementação}

Aproveitando do fato que as classes que implementam os algoritmos de
classificação seguem a mesma interface, implementamos o algoritmo de testes dos
classificadores utilizando técnicas de reflexão. Essas técnicas permitiram que o
algoritmo de teste ficasse mais generalista e resumido, uma vez que não é
necessário implementar um teste específico para cada algoritmo.

Devido ao alto tempo de execução e a alta possibilidade de paralelismo,
utilizamos o módulo de multiprocessamento do Python para diminuir o tempo de
execução dos testes e fazer melhor uso dos recursos computacionais. A
quantidade de subprocessos é determinada pela quantidade de processadores
disponíveis no ambiente que o algoritmo é executado (4 subprocessos utilizando
a máquina de testes descrita anteriormente).

Além da execução paralela, duas pequenas otimizações foram feitas com o intuito
de dimiuir o tempo de processamento. Duas técnicas foram utilizadas:
\textit{lazy load} dos datasets e uma otimização do algoritmo \textit{minmax}
em que reduzimos a complexidade de $O(n^2)$ para $O(n)$.


Pelo mesmo motivo de tempo de execução apontado anteriormente, implementamos um
mecanismo de retomada da execução do algoritmo de testes: a cada uma das cem
iterações salvamos o estado da execução. O algoritmo continua a execução de
onde parou caso uma parada aconteça.

\subsection{Pré-processamento de dados}

Com exceção da base de dados \textit{banknot}, as bases de dados contêm
atributos não-numéricos que precisam ser tratados antes. Esses atributos foram
substituídos por valores inteiros com o intuito de permitir o uso nos
classificadores. Esse pré-processamento pode ser analisado no arquivo
\textit{main.py} na função \textit{trata\_datasets()}.

Além disso, todos os dados numéricos (exceto as classes) foram normalizados
utilizando a técnica \textbf{minmax} ($minmax(X) = {x-Min(X)\over{Max(X)-Min(X)}}, \forall x \in X)$. 
O minmax normaliza os dados no intervalo $[0,1]$ e isso é especialmente
interessante para os classificadores Bayesianos, os quais não aceitam entradas
negativas.

\section{Resultados}
\section{Considerações finais}
\section{Referências}
\section{Anexos}
\subsection{Matrizes de confusão}


\end{document}
